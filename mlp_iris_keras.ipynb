{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp_iris_keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOsSp+HNFZW0O9euAKF04AH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anusree-t-s/deep-learning/blob/master/mlp_iris_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlKOmc9nLpku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# Load the dataset from sklearn\n",
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba8PFDbbLx_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing both TensorFlow and its high level API - Keras.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# Setting the random seeds for repeatability\n",
        "tf.set_random_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Loading the dataset\n",
        "irisData = load_iris()\n",
        "\n",
        "# Load the attributes and target in X and y\n",
        "X = irisData.data\n",
        "y = irisData.target\n",
        "\n",
        "# Split the data into 80% training and 20% testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJb2pBhvL3yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature scaling using Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "# Training the feature scaling parameters\n",
        "sc.fit(X_train)\n",
        "# Applying transformations to both training and testing set\n",
        "X_train_std = sc.transform(X_train)\n",
        "X_test_std = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5GqnzlxL9p3",
        "colab_type": "code",
        "outputId": "ecc6cb7c-9db2-49ce-f59c-5bd96653b2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Create neural network using keras API\n",
        "# Sequential() does linear stacking of layer\n",
        "model_MLP = keras.models.Sequential()\n",
        "# Hidden layer definitions\n",
        "model_MLP.add(keras.layers.Dense(units=15, activation='relu',\n",
        "input_shape= X_train.shape[1:]))\n",
        "# Output layer definitions\n",
        "model_MLP.add(keras.layers.Dense(units=3, activation='softmax'))\n",
        "\n",
        "# Print the summary of network architecture\n",
        "model_MLP.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 15)                75        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 48        \n",
            "=================================================================\n",
            "Total params: 123\n",
            "Trainable params: 123\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a6JBPXfMFe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_MLP.compile(loss='sparse_categorical_crossentropy',\n",
        "optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sylaRokKMThe",
        "colab_type": "code",
        "outputId": "953e807f-2f57-43bf-b326-9734d8bd741e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_MLP.fit(x=X_train_std, y=y_train, validation_split=0.1,\n",
        "epochs=50, batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 108 samples, validate on 12 samples\n",
            "Epoch 1/50\n",
            "108/108 [==============================] - 0s 2ms/sample - loss: 1.2136 - acc: 0.2870 - val_loss: 1.2068 - val_acc: 0.2500\n",
            "Epoch 2/50\n",
            "108/108 [==============================] - 0s 137us/sample - loss: 1.1591 - acc: 0.3704 - val_loss: 1.1464 - val_acc: 0.3333\n",
            "Epoch 3/50\n",
            "108/108 [==============================] - 0s 129us/sample - loss: 1.1060 - acc: 0.4259 - val_loss: 1.0904 - val_acc: 0.5000\n",
            "Epoch 4/50\n",
            "108/108 [==============================] - 0s 124us/sample - loss: 1.0571 - acc: 0.5093 - val_loss: 1.0356 - val_acc: 0.5833\n",
            "Epoch 5/50\n",
            "108/108 [==============================] - 0s 118us/sample - loss: 1.0095 - acc: 0.5463 - val_loss: 0.9840 - val_acc: 0.5833\n",
            "Epoch 6/50\n",
            "108/108 [==============================] - 0s 113us/sample - loss: 0.9667 - acc: 0.5556 - val_loss: 0.9352 - val_acc: 0.5833\n",
            "Epoch 7/50\n",
            "108/108 [==============================] - 0s 112us/sample - loss: 0.9246 - acc: 0.5648 - val_loss: 0.8918 - val_acc: 0.5833\n",
            "Epoch 8/50\n",
            "108/108 [==============================] - 0s 111us/sample - loss: 0.8855 - acc: 0.5926 - val_loss: 0.8520 - val_acc: 0.5833\n",
            "Epoch 9/50\n",
            "108/108 [==============================] - 0s 112us/sample - loss: 0.8495 - acc: 0.6204 - val_loss: 0.8132 - val_acc: 0.7500\n",
            "Epoch 10/50\n",
            "108/108 [==============================] - 0s 123us/sample - loss: 0.8158 - acc: 0.6389 - val_loss: 0.7776 - val_acc: 0.7500\n",
            "Epoch 11/50\n",
            "108/108 [==============================] - 0s 103us/sample - loss: 0.7823 - acc: 0.6759 - val_loss: 0.7470 - val_acc: 0.7500\n",
            "Epoch 12/50\n",
            "108/108 [==============================] - 0s 136us/sample - loss: 0.7514 - acc: 0.7222 - val_loss: 0.7175 - val_acc: 0.7500\n",
            "Epoch 13/50\n",
            "108/108 [==============================] - 0s 128us/sample - loss: 0.7215 - acc: 0.7593 - val_loss: 0.6926 - val_acc: 0.7500\n",
            "Epoch 14/50\n",
            "108/108 [==============================] - 0s 138us/sample - loss: 0.6936 - acc: 0.7778 - val_loss: 0.6679 - val_acc: 0.7500\n",
            "Epoch 15/50\n",
            "108/108 [==============================] - 0s 133us/sample - loss: 0.6663 - acc: 0.7870 - val_loss: 0.6460 - val_acc: 0.7500\n",
            "Epoch 16/50\n",
            "108/108 [==============================] - 0s 163us/sample - loss: 0.6414 - acc: 0.8148 - val_loss: 0.6264 - val_acc: 0.7500\n",
            "Epoch 17/50\n",
            "108/108 [==============================] - 0s 114us/sample - loss: 0.6164 - acc: 0.8241 - val_loss: 0.6086 - val_acc: 0.7500\n",
            "Epoch 18/50\n",
            "108/108 [==============================] - 0s 120us/sample - loss: 0.5936 - acc: 0.8519 - val_loss: 0.5930 - val_acc: 0.7500\n",
            "Epoch 19/50\n",
            "108/108 [==============================] - 0s 118us/sample - loss: 0.5716 - acc: 0.8704 - val_loss: 0.5786 - val_acc: 0.7500\n",
            "Epoch 20/50\n",
            "108/108 [==============================] - 0s 141us/sample - loss: 0.5508 - acc: 0.8796 - val_loss: 0.5649 - val_acc: 0.7500\n",
            "Epoch 21/50\n",
            "108/108 [==============================] - 0s 127us/sample - loss: 0.5321 - acc: 0.8796 - val_loss: 0.5528 - val_acc: 0.7500\n",
            "Epoch 22/50\n",
            "108/108 [==============================] - 0s 125us/sample - loss: 0.5136 - acc: 0.8796 - val_loss: 0.5414 - val_acc: 0.7500\n",
            "Epoch 23/50\n",
            "108/108 [==============================] - 0s 132us/sample - loss: 0.4971 - acc: 0.8889 - val_loss: 0.5301 - val_acc: 0.7500\n",
            "Epoch 24/50\n",
            "108/108 [==============================] - 0s 134us/sample - loss: 0.4812 - acc: 0.8889 - val_loss: 0.5200 - val_acc: 0.7500\n",
            "Epoch 25/50\n",
            "108/108 [==============================] - 0s 140us/sample - loss: 0.4679 - acc: 0.8889 - val_loss: 0.5132 - val_acc: 0.7500\n",
            "Epoch 26/50\n",
            "108/108 [==============================] - 0s 170us/sample - loss: 0.4540 - acc: 0.8889 - val_loss: 0.5037 - val_acc: 0.7500\n",
            "Epoch 27/50\n",
            "108/108 [==============================] - 0s 126us/sample - loss: 0.4412 - acc: 0.8981 - val_loss: 0.4942 - val_acc: 0.7500\n",
            "Epoch 28/50\n",
            "108/108 [==============================] - 0s 130us/sample - loss: 0.4303 - acc: 0.8981 - val_loss: 0.4865 - val_acc: 0.7500\n",
            "Epoch 29/50\n",
            "108/108 [==============================] - 0s 123us/sample - loss: 0.4192 - acc: 0.9074 - val_loss: 0.4786 - val_acc: 0.7500\n",
            "Epoch 30/50\n",
            "108/108 [==============================] - 0s 120us/sample - loss: 0.4090 - acc: 0.9074 - val_loss: 0.4700 - val_acc: 0.7500\n",
            "Epoch 31/50\n",
            "108/108 [==============================] - 0s 117us/sample - loss: 0.3995 - acc: 0.9074 - val_loss: 0.4615 - val_acc: 0.7500\n",
            "Epoch 32/50\n",
            "108/108 [==============================] - 0s 117us/sample - loss: 0.3903 - acc: 0.9074 - val_loss: 0.4533 - val_acc: 0.7500\n",
            "Epoch 33/50\n",
            "108/108 [==============================] - 0s 138us/sample - loss: 0.3820 - acc: 0.9074 - val_loss: 0.4477 - val_acc: 0.7500\n",
            "Epoch 34/50\n",
            "108/108 [==============================] - 0s 123us/sample - loss: 0.3738 - acc: 0.9167 - val_loss: 0.4426 - val_acc: 0.7500\n",
            "Epoch 35/50\n",
            "108/108 [==============================] - 0s 116us/sample - loss: 0.3659 - acc: 0.9074 - val_loss: 0.4355 - val_acc: 0.7500\n",
            "Epoch 36/50\n",
            "108/108 [==============================] - 0s 122us/sample - loss: 0.3585 - acc: 0.9074 - val_loss: 0.4290 - val_acc: 0.7500\n",
            "Epoch 37/50\n",
            "108/108 [==============================] - 0s 112us/sample - loss: 0.3517 - acc: 0.9074 - val_loss: 0.4218 - val_acc: 0.7500\n",
            "Epoch 38/50\n",
            "108/108 [==============================] - 0s 128us/sample - loss: 0.3451 - acc: 0.9074 - val_loss: 0.4153 - val_acc: 0.7500\n",
            "Epoch 39/50\n",
            "108/108 [==============================] - 0s 111us/sample - loss: 0.3387 - acc: 0.9074 - val_loss: 0.4089 - val_acc: 0.7500\n",
            "Epoch 40/50\n",
            "108/108 [==============================] - 0s 147us/sample - loss: 0.3328 - acc: 0.9074 - val_loss: 0.4033 - val_acc: 0.7500\n",
            "Epoch 41/50\n",
            "108/108 [==============================] - 0s 141us/sample - loss: 0.3272 - acc: 0.9074 - val_loss: 0.3963 - val_acc: 0.7500\n",
            "Epoch 42/50\n",
            "108/108 [==============================] - 0s 155us/sample - loss: 0.3217 - acc: 0.9074 - val_loss: 0.3912 - val_acc: 0.7500\n",
            "Epoch 43/50\n",
            "108/108 [==============================] - 0s 117us/sample - loss: 0.3163 - acc: 0.9074 - val_loss: 0.3859 - val_acc: 0.7500\n",
            "Epoch 44/50\n",
            "108/108 [==============================] - 0s 109us/sample - loss: 0.3112 - acc: 0.9074 - val_loss: 0.3802 - val_acc: 0.7500\n",
            "Epoch 45/50\n",
            "108/108 [==============================] - 0s 137us/sample - loss: 0.3063 - acc: 0.9074 - val_loss: 0.3747 - val_acc: 0.7500\n",
            "Epoch 46/50\n",
            "108/108 [==============================] - 0s 132us/sample - loss: 0.3018 - acc: 0.9074 - val_loss: 0.3683 - val_acc: 0.7500\n",
            "Epoch 47/50\n",
            "108/108 [==============================] - 0s 129us/sample - loss: 0.2973 - acc: 0.9074 - val_loss: 0.3629 - val_acc: 0.7500\n",
            "Epoch 48/50\n",
            "108/108 [==============================] - 0s 145us/sample - loss: 0.2929 - acc: 0.9074 - val_loss: 0.3568 - val_acc: 0.7500\n",
            "Epoch 49/50\n",
            "108/108 [==============================] - 0s 123us/sample - loss: 0.2885 - acc: 0.9167 - val_loss: 0.3524 - val_acc: 0.7500\n",
            "Epoch 50/50\n",
            "108/108 [==============================] - 0s 122us/sample - loss: 0.2845 - acc: 0.9167 - val_loss: 0.3473 - val_acc: 0.7500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f83f9467908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IgYefNYMdmh",
        "colab_type": "code",
        "outputId": "ef8f5abe-7a9d-4db8-8035-9a14076cb9ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "test_loss, test_accuracy = model_MLP.evaluate(x=X_test_std, y=y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r30/30 [==============================] - 0s 39us/sample - loss: 0.3645 - acc: 0.8333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7ilUPWWMiPG",
        "colab_type": "code",
        "outputId": "819cd589-05ee-498f-d172-76f5855ead65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(test_loss, test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3645183742046356 0.8333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWTttxuoMknc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}